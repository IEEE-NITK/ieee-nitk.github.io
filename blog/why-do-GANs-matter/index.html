<!DOCTYPE html>
<html lang="pt-br">
        <head>
        <!-- Give a small description in 3-4 sentences about the website -->
        <meta name="abstract" content="IEEE NITK Student Chapter under Mangalore SubSection and Bangalore Section was founded in 1988. Currently it has three SIGs namely Computer Society, Circuits and Systems, Signal Processing Society and Piston. It also has two Affinty Groups namely Special Interest Group in Humanitarian Technologies (SIGHT) and Women in Engineering (WiE)">
        <!-- Important Keywords to be noted in the website  -->
        <meta name="keywords" content="IEEE, IEEE NITK, NITK Surathkal, NITK, Clubs in NITK, Technical Clubs in NITK">
        <!-- Tell the spider to index the first page and other pages as well-->
        <meta name="robots" content="index, follow">    
        <!-- How often should spiders come back to your page -->
        <meta name="revisit-after" content="3 days">

        <!-- Copyright regarding the website -->
        <meta name="copyright" content="IEEE NITK">
        <!-- Tells Google Bot not to duplicate description -->
        <meta name="googlebot" content="noodp">
        <!-- Language for the website -->
        <meta name="language" content="English">  

        <!-- Web Author for the image -->
        <meta name="web_author" content="IEEE NITK">
        <meta name="author" content="Salman Shah">
        <!-- Email ID -->
        <meta name="contact" content="ieee@nitk.edu.in" />
        <!-- Email ID to reply to -->
        <meta name="reply-to" content="ieee@nitk.edu.in">

        <!-- Refers to distribution of the page -->
        <meta name="distribution" content="global">
        <!-- Generator or formatter tag -->
        <meta name="generator" content="Jekyll">
        <!-- Disallow spammers for the webpage -->
        <meta name="no-email-collection" content="http://www.metatags.info/nospamharvesting">
        <!-- Rating for the page -->
        <meta name="rating" content="general">
        <!-- Content Type for the page -->
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
        <!-- Fixing viewport on mobile views -->
        <meta name="viewport" content="width=device-width; initial-scale=1; maximum-scale=1.0">

        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">

        <meta name="description" content="What can we gain from GANs?">

        <!-- Google Authorship Markup -->
        <!-- Social: Twitter -->
        <meta name="twitter:card" content="summary_large_image">
        <meta name="twitter:site" content="@IEEE_NITK">
        <meta name="twitter:title" content="Why do Generative Adversarial Nets matter?">
        <meta name="twitter:description" content="What can we gain from GANs?">
        <meta property="twitter:image:src" content="https://ieee.nitk.ac.in/blog/assets/img/blog-image.png">

        <!-- Social: Facebook / Open Graph -->
        <meta property="fb:app_id" content="0011038251882641" />
        <meta property="og:url" content="https://ieee.nitk.ac.in/blog/why-do-GANs-matter/" />
        <meta property="og:title" content="Why do Generative Adversarial Nets matter?">
        <meta property="og:image" content="https://ieee.nitk.ac.in/blog/assets/img/blog-image.png">
        <meta property="og:description" content="What can we gain from GANs?">
        <meta property="og:site_name" content="A blog about our findings and musings">

        <!-- Social: Google+ / Schema.org  -->
        <meta itemprop="name" content="Why do Generative Adversarial Nets matter?"/>
        <meta itemprop="description" content="What can we gain from GANs?">
        <meta itemprop="image" content="https://ieee.nitk.ac.in/blog/assets/img/blog-image.png"/>
        <meta name="msapplication-TileColor" content="#ffffff">
        <meta name="msapplication-TileImage" content="/ms-icon-144x144.png">
        <meta name="theme-color" content="#ffffff">

        <!-- Windows 8 Tile Icons -->
        <meta name="application-name" content="IEEE-NITK Blog">
        <meta name="msapplication-TileColor" content="#0562DC">
        <meta name="msapplication-square70x70logo" content="smalltile.png" />
        <meta name="msapplication-square150x150logo" content="mediumtile.png" />
        <meta name="msapplication-wide310x150logo" content="widetile.png" />
        <meta name="msapplication-square310x310logo" content="largetile.png" />
        
        <!-- Android Lolipop Theme Color -->
        <meta name="theme-color" content="#0562DC">

        <link rel="author" href="https://plus.google.com/?rel=author">

        <!-- Favicon -->
        <link rel="shortcut icon" href="/blog/assets/img/icons/favicon.ico" type="image/x-icon" />
        <link rel="manifest" href="/blog/assets/img/icons/manifest.json">
        <!-- Include Font Awesome -->
        <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">

        <title>Why do Generative Adversarial Nets matter?</title>

        <!-- highlighter theme -->
        <link rel="stylesheet" href="/blog/assets/css/monokai-sublime.css">

        <link rel="stylesheet" href="/blog/assets/css/main.css">
        <link rel="canonical" href="/blog/why-do-GANs-matter/">
        <link rel="alternate" type="application/rss+xml" title="A blog about our findings and musings"
        href="https://ieee.nitk.ac.in/blog/feed.xml" />

        

        <!-- jQuery for highlighter -->
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.2.4/jquery.min.js"></script>
        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-106590424-3"></script>
        <script src="/blog/assets/js/sidebar.js"></script>
        <script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());

            gtag('config', 'UA-106590424-3');
            $(document).ready(function(){
                loadArticles();
            });
        </script>

    </head>

    <body>
        <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" display="none" version="1.1"><defs><symbol id="icon-menu" viewBox="0 0 1024 1024"><path class="path1" d="M128 213.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5zM128 725.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5zM128 469.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5z"/></symbol><symbol id="icon-search" viewBox="0 0 951 1024"><path class="path1" d="M658.286 475.429q0-105.714-75.143-180.857t-180.857-75.143-180.857 75.143-75.143 180.857 75.143 180.857 180.857 75.143 180.857-75.143 75.143-180.857zM950.857 950.857q0 29.714-21.714 51.429t-51.429 21.714q-30.857 0-51.429-21.714l-196-195.429q-102.286 70.857-228 70.857-81.714 0-156.286-31.714t-128.571-85.714-85.714-128.571-31.714-156.286 31.714-156.286 85.714-128.571 128.571-85.714 156.286-31.714 156.286 31.714 128.571 85.714 85.714 128.571 31.714 156.286q0 125.714-70.857 228l196 196q21.143 21.143 21.143 51.429z"/></symbol><symbol id="icon-email" viewBox="0 0 1024 1024"><path class="path1" d="M950.857 859.429v-438.857q-18.286 20.571-39.429 37.714-153.143 117.714-243.429 193.143-29.143 24.571-47.429 38.286t-49.429 27.714-58.571 14h-1.143q-27.429 0-58.571-14t-49.429-27.714-47.429-38.286q-90.286-75.429-243.429-193.143-21.143-17.143-39.429-37.714v438.857q0 7.429 5.429 12.857t12.857 5.429h841.143q7.429 0 12.857-5.429t5.429-12.857zM950.857 258.857v-14t-0.286-7.429-1.714-7.143-3.143-5.143-5.143-4.286-8-1.429h-841.143q-7.429 0-12.857 5.429t-5.429 12.857q0 96 84 162.286 110.286 86.857 229.143 181.143 3.429 2.857 20 16.857t26.286 21.429 25.429 18 28.857 15.714 24.571 5.143h1.143q11.429 0 24.571-5.143t28.857-15.714 25.429-18 26.286-21.429 20-16.857q118.857-94.286 229.143-181.143 30.857-24.571 57.429-66t26.571-75.143zM1024 237.714v621.714q0 37.714-26.857 64.571t-64.571 26.857h-841.143q-37.714 0-64.571-26.857t-26.857-64.571v-621.714q0-37.714 26.857-64.571t64.571-26.857h841.143q37.714 0 64.571 26.857t26.857 64.571z"/></symbol><symbol id="icon-close" viewBox="0 0 805 1024"><path class="path1" d="M741.714 755.429q0 22.857-16 38.857l-77.714 77.714q-16 16-38.857 16t-38.857-16l-168-168-168 168q-16 16-38.857 16t-38.857-16l-77.714-77.714q-16-16-16-38.857t16-38.857l168-168-168-168q-16-16-16-38.857t16-38.857l77.714-77.714q16-16 38.857-16t38.857 16l168 168 168-168q16-16 38.857-16t38.857 16l77.714 77.714q16 16 16 38.857t-16 38.857l-168 168 168 168q16 16 16 38.857z"/></symbol><symbol id="icon-twitter" viewBox="0 0 951 1024"><path class="path1" d="M925.714 233.143q-38.286 56-92.571 95.429 0.571 8 0.571 24 0 74.286-21.714 148.286t-66 142-105.429 120.286-147.429 83.429-184.571 31.143q-154.857 0-283.429-82.857 20 2.286 44.571 2.286 128.571 0 229.143-78.857-60-1.143-107.429-36.857t-65.143-91.143q18.857 2.857 34.857 2.857 24.571 0 48.571-6.286-64-13.143-106-63.714t-42-117.429v-2.286q38.857 21.714 83.429 23.429-37.714-25.143-60-65.714t-22.286-88q0-50.286 25.143-93.143 69.143 85.143 168.286 136.286t212.286 56.857q-4.571-21.714-4.571-42.286 0-76.571 54-130.571t130.571-54q80 0 134.857 58.286 62.286-12 117.143-44.571-21.143 65.714-81.143 101.714 53.143-5.714 106.286-28.571z"/></symbol><symbol id="icon-facebook" viewBox="0 0 585 1024"><path class="path1" d="M548 6.857v150.857h-89.714q-49.143 0-66.286 20.571t-17.143 61.714v108h167.429l-22.286 169.143h-145.143v433.714h-174.857v-433.714h-145.714v-169.143h145.714v-124.571q0-106.286 59.429-164.857t158.286-58.571q84 0 130.286 6.857z"/></symbol><symbol id="icon-rss" viewBox="0 0 805 1024"><path class="path1" d="M219.429 768q0 45.714-32 77.714t-77.714 32-77.714-32-32-77.714 32-77.714 77.714-32 77.714 32 32 77.714zM512 838.286q1.143 16-9.714 27.429-10.286 12-26.857 12h-77.143q-14.286 0-24.571-9.429t-11.429-23.714q-12.571-130.857-105.429-223.714t-223.714-105.429q-14.286-1.143-23.714-11.429t-9.429-24.571v-77.143q0-16.571 12-26.857 9.714-9.714 24.571-9.714h2.857q91.429 7.429 174.857 46t148 103.714q65.143 64.571 103.714 148t46 174.857zM804.571 839.429q1.143 15.429-10.286 26.857-10.286 11.429-26.286 11.429h-81.714q-14.857 0-25.429-10t-11.143-24.286q-6.857-122.857-57.714-233.429t-132.286-192-192-132.286-233.429-58.286q-14.286-0.571-24.286-11.143t-10-24.857v-81.714q0-16 11.429-26.286 10.286-10.286 25.143-10.286h1.714q149.714 7.429 286.571 68.571t243.143 168q106.857 106.286 168 243.143t68.571 286.571z"/></symbol><symbol id="icon-google-plus" viewBox="0 0 951 1024"><path class="path1" d="M420 454.857q0 20.571 18.286 40.286t44.286 38.857 51.714 42 44 59.429 18.286 81.143q0 51.429-27.429 98.857-41.143 69.714-120.571 102.571t-170.286 32.857q-75.429 0-140.857-23.714t-98-78.571q-21.143-34.286-21.143-74.857 0-46.286 25.429-85.714t67.714-65.714q74.857-46.857 230.857-57.143-18.286-24-27.143-42.286t-8.857-41.714q0-20.571 12-48.571-26.286 2.286-38.857 2.286-84.571 0-142.571-55.143t-58-139.714q0-46.857 20.571-90.857t56.571-74.857q44-37.714 104.286-56t124.286-18.286h238.857l-78.857 50.286h-74.857q42.286 36 64 76t21.714 91.429q0 41.143-14 74t-33.714 53.143-39.714 37.143-34 35.143-14 37.714zM336.571 400q21.714 0 44.571-9.429t37.714-24.857q30.286-32.571 30.286-90.857 0-33.143-9.714-71.429t-27.714-74-48.286-59.143-66.857-23.429q-24 0-47.143 11.143t-37.429 30q-26.857 33.714-26.857 91.429 0 26.286 5.714 55.714t18 58.857 29.714 52.857 42.857 38.286 55.143 14.857zM337.714 898.857q33.143 0 63.714-7.429t56.571-22.286 41.714-41.714 15.714-62.286q0-14.286-4-28t-8.286-24-15.429-23.714-16.857-20-22-19.714-20.857-16.571-23.714-17.143-20.857-14.857q-9.143-1.143-27.429-1.143-30.286 0-60 4t-61.429 14.286-55.429 26.286-39.143 42.571-15.429 60.286q0 40 20 70.571t52.286 47.429 68 25.143 72.857 8.286zM800.571 398.286h121.714v61.714h-121.714v125.143h-60v-125.143h-121.143v-61.714h121.143v-124h60v124z"/></symbol><symbol id="icon-angle-down" viewBox="0 0 658 1024"><path class="path1" d="M614.286 420.571q0 7.429-5.714 13.143l-266.286 266.286q-5.714 5.714-13.143 5.714t-13.143-5.714l-266.286-266.286q-5.714-5.714-5.714-13.143t5.714-13.143l28.571-28.571q5.714-5.714 13.143-5.714t13.143 5.714l224.571 224.571 224.571-224.571q5.714-5.714 13.143-5.714t13.143 5.714l28.571 28.571q5.714 5.714 5.714 13.143z"/></symbol><symbol id="icon-github-alt" viewBox="0 0 951 1024"><path class="path1" d="M365.714 694.857q0 22.857-7.143 46.857t-24.571 43.429-41.429 19.429-41.429-19.429-24.571-43.429-7.143-46.857 7.143-46.857 24.571-43.429 41.429-19.429 41.429 19.429 24.571 43.429 7.143 46.857zM731.429 694.857q0 22.857-7.143 46.857t-24.571 43.429-41.429 19.429-41.429-19.429-24.571-43.429-7.143-46.857 7.143-46.857 24.571-43.429 41.429-19.429 41.429 19.429 24.571 43.429 7.143 46.857zM822.857 694.857q0-68.571-39.429-116.571t-106.857-48q-23.429 0-111.429 12-40.571 6.286-89.714 6.286t-89.714-6.286q-86.857-12-111.429-12-67.429 0-106.857 48t-39.429 116.571q0 50.286 18.286 87.714t46.286 58.857 69.714 34.286 80 16.857 85.143 4h96q46.857 0 85.143-4t80-16.857 69.714-34.286 46.286-58.857 18.286-87.714zM950.857 594.286q0 118.286-34.857 189.143-21.714 44-60.286 76t-80.571 49.143-97.143 27.143-98 12.571-95.429 2.571q-44.571 0-81.143-1.714t-84.286-7.143-87.143-17.143-78.286-29.429-69.143-46.286-49.143-65.714q-35.429-70.286-35.429-189.143 0-135.429 77.714-226.286-15.429-46.857-15.429-97.143 0-66.286 29.143-124.571 61.714 0 108.571 22.571t108 70.571q84-20 176.571-20 84.571 0 160 18.286 60-46.857 106.857-69.143t108-22.286q29.143 58.286 29.143 124.571 0 49.714-15.429 96 77.714 91.429 77.714 227.429z"/></symbol></defs></svg>

        <header class="header-post" role="banner">
    <div class="content">
        
            <time itemprop="datePublished" datetime="2019-11-10 10:35:00 +0530" class="date">10 Nov 2019</time>
        
        <h1 class="post-title" itemprop="name">Why do Generative Adversarial Nets matter?</h1>
        <p itemprop="description" class="subtitle">What can we gain from GANs?</p>
    </div>
     <a class="down" data-scroll href="#scroll"><svg class="icon icon-angle-down"><use xlink:href="#icon-angle-down"></use></svg></a>
     <div class="search-wrapper">
    <div class="search-form">
        <input type="text" class="search-field" placeholder="Search...">
        <svg class="icon-remove-sign"><use xlink:href="#icon-close"></use></svg>
        <ul class="search-results search-list"></ul>
    </div>
</div>

<div id="fade" class="overlay"></div>
<a id="slide" class="slideButton fade">
    <svg id="open" class="icon-menu"><use xlink:href="#icon-menu"></use></svg>
    <svg id="close" class="icon-menu"><use xlink:href="#icon-close"></use></svg>
</a>
<aside id="sidebar">
<nav id="navigation">
  <h2>MENU</h2>
  <ul>
    
    
      <li><a href="https://ieee.nitk.ac.in/blog">Home</a></li>
    
    
    
      <li><a href="https://ieee.nitk.ac.in/blog/tags">Tags</a></li>
    
    
    
      <li><a href="https://ieee.nitk.ac.in/">Main Website</a></li>
    
    
    
      <li><a href="https://ieee.nitk.ac.in/gyan">Gyan</a></li>
    
    
    <li><a class="feed" href="https://ieee.nitk.ac.in/blog/feed.xml" title="Atom/RSS feed">Feed</a></li>
  </ul>
</nav>
</aside>
<a id="search" class="dosearch">
    <svg class="icon-menu icon-search"><use xlink:href="#icon-search"></use></svg>
</a>

</header>

        <section class="post" itemscope itemtype="http://schema.org/BlogPosting">

            <div class="content-box">
                <article role="article" id="scroll" class="post-content" itemprop="articleBody">
                    <p>A new class of <strong>Generative Models</strong> was proposed in 2014 by <strong>Ian Goodfellow</strong> (a.k.a The GANfather) which brought in a novel method of dealing with issues in ML and AI. The Invention of <strong>Generative Adversarial Networks</strong> (GANs) can be regarded as one of the path-breaking innovations in making computers do useful stuff. GANs have seen some crazy development from an application perspective and has been one of the hottest topics for research in the past 5 years.</p>

<h2 id="so-what-does-a-generative-model-do">So what does a Generative Model do?</h2>

<p>The main objective of a Generative Model is to create more samples of the <strong>same</strong> type as training data. The basic idea is to take a set of training examples and develop a <strong>probability distribution</strong>. Based on that distribution, it generates more samples. There are two ways of generative modeling - one is to explicitly define a <strong>density function</strong>, for instance, a Gaussian density function or log-likelihood which tells the probability distribution that generated them and the other is observing many samples from a particular distribution and generating more samples from the same distribution. GANs come under the latter category, where learning the function is left to the model itself.</p>

<h2 id="how-do-gans-work">How do GANs work?</h2>

<p>GANs form a subclass of <strong>implicit</strong> Generative models that rely on adversarial training of two networks: the <strong>Generator G</strong>, which attempts to produce samples that mimic the <strong>reference distribution</strong>, and the <strong>Discriminator D</strong>, which tries to differentiate between real and generated samples and, in doing so, provides a useful gradient signal to the Generator. GANs have proven to be useful in various domains like unsupervised feature learning, image and video generation. They are illustrated with an analogy in the image.</p>

<p><img src="/blog/assets/img/why-do-GANs-matter/GAN_structure.png" alt="Generative Adversarial Network" /></p>

<h2 id="why-are-generative-models-useful">Why are Generative Models useful?</h2>

<p>The first question that comes to mind is that why do we even care about generating more samples (say images) with tons of them lying around? The applications are pleasing enough to reason for it:</p>

<ul>
  <li>Generative models can be used in <strong>Curiosity-driven Exploration</strong> in Deep Reinforcement Learning. One of the biggest problems in RL is balanced <strong>Exploration</strong> and <strong>Exploitation</strong> in high dimensional space. Without efficient Exploration techniques, the agent may just wander around until it stumbles into a rewarding state. This can waste a lot of computation and training time even if we use a heuristic approach. In this <a href="https://arxiv.org/abs/1605.09674">paper</a>, Rein Houthooft and colleagues propose <strong>VIME</strong>, a practical approach to exploration using uncertainty on Generative models.</li>
</ul>

<p>The following illustration compares the two approaches. The agent in the left is trained using <strong>VIME</strong> approach while the right one using <strong>Naive</strong> approach.</p>

<table>
  <tbody>
    <tr>
      <td><img src="/blog/assets/img/why-do-GANs-matter/policy_with_VIME.gif" alt="VIME approach" /></td>
      <td><img src="/blog/assets/img/why-do-GANs-matter/policy_naive.gif" alt="Naive approach" /></td>
    </tr>
  </tbody>
</table>

<ul>
  <li>
    <p>We can use Generative models to simulate possible futures for Reinforcement Learning. We can have an agent learn in a simulated environment built entirely using generative models rather than building it physically. The advantage of using this model-based RL approach is that it can be <strong>parallelized</strong> easily across different machines and the mistakes in it are not as costly as if we make them in the real world.</p>
  </li>
  <li>
    <p>Generative models can to fill in missing inputs and learn even when some of the labels in the data are missing. They handle missing inputs much more effectively than the traditional input to output mappings in machine learning models. <a href="https://arxiv.org/abs/1806.02920"><strong>GAINs</strong></a> are a type of GANs where the generator imputes a vector of real data, which is then fed back to the discriminator to figure out which data was originally missing. <a href="https://openreview.net/forum?id=S1lDV3RcKm"><strong>MisGAN</strong></a> is another variety that can learn from complex, higher-dimensional incomplete data using a <strong>pair</strong> of generators and discriminators. <strong>Semi-Supervised Learning</strong> is an application where we may have very few labeled inputs but by leveraging many more unlabeled examples, we can do good on the test set.</p>
  </li>
</ul>

<p><img src="/blog/assets/img/why-do-GANs-matter/face_application.jpg" alt="MSE v/s Adversarial appraoch" /></p>

<ul>
  <li>The picture shows two approaches to finding the next frame in the video. Since there are many possibilities in a video in the next time step, traditional approaches like <strong>Mean Squared Error</strong> (MSE), result in the output being a bit blurry as a consequence of averaging out various results. Using generative techniques and <strong>adversarial</strong> particularly results in getting a sharp output towards the eyes as well as ears.</li>
</ul>

<h2 id="gans-demystified">GANs Demystified…</h2>

<p>GANs are turning out to be better than the traditional approaches in various applications of Machine Learning. Following are some of the recent developments in GANs:</p>

<h3 id="high-fidelity-speech-synthesis-with-gans">High Fidelity Speech Synthesis with GANs</h3>

<p>The <strong>Text-to-Speech</strong> (TTS) task consists of the conversion of text into speech audio. There has been a lot of development in this field using <a href="https://arxiv.org/abs/1605.02226"><strong>Neural Autoregressive models</strong></a>. However, an essential disadvantage of this technique is that it is difficult to parallelize. Every time step in the audio needs to be considered <strong>sequentially</strong> which is computationally expensive.</p>

<p>Using GANs can help in parallel waveform generation. <strong>GAN-TTS</strong>, a Generative Adversarial Network for Text-to-Speech is a novel architecture proposed for this. It consists of a feed-forward generator, which is a Convolutional Neural Network, paired with an <strong>ensemble</strong> of multiple discriminators which evaluate the generated and real data. <a href="https://en.wikipedia.org/wiki/Mean_opinion_score">Mean Opinion Score</a> (MOS), as well as quantitative metrics - <a href="https://en.wikipedia.org/wiki/Fr%C3%A9chet_distance">Frechet DeepSpeech Distance</a> and Kernel DeepSpeech Distance, are used as evaluation metrics.</p>

<p><img src="/blog/assets/img/why-do-GANs-matter/subtopic1.png" alt="GAN-TTS architecture" /></p>

<p>The generator’s input is pitch and linguistic features and output is a raw waveform at a certain frequency. <strong>GBlock</strong> shows the design of the generator in the above diagram. The output convolutional layer uses <strong>tanh</strong> activation function to produce a single-channel audio waveform. The discriminator consists of an ensemble instead of a single model as in <strong>DBlock</strong>. Some discriminators take the linguistic conditioning into account while others ignore the conditioning and can only assess the general realism of the audio.</p>

<h3 id="connecting-gans-and-actor-critic-methods-in-rl">Connecting GANs and Actor-Critic methods in RL</h3>

<p>Both GANs in unsupervised Learning and Actor-Critic methods in Reinforcement Learning are difficult to optimize and stabilize since they often end up giving <strong>degenerate solutions</strong>. Both are multi-level optimization methods where we do not have a single unified objective function and consist of hybrid models where each tries to minimize its <strong>private cost function</strong>. Each level is optimized with respect to the optimum of the other model. This makes the traditional optimization methods like <em>Gradient Descent</em> and its variants not work very well since they are oriented towards solving a common cost function.</p>

<p><img src="/blog/assets/img/why-do-GANs-matter/subtopic2.1.png" alt="GANs and AC methods cycle" /></p>

<p>The main aim of AC methods is to simultaneously learn an <strong>action-value</strong> function along with a <strong>policy</strong>, thereby predicting the reward, while GANs learn to produce more samples of the same type as training data. Both have a feed-forward propagation step where one model controls the agent’s behavior (Actor <strong>A</strong>) or generates samples (Generator <strong>G</strong>) and the second evaluates how good the action is (Critic <strong>C</strong>) or classifies samples as fake or real (Discriminator <strong>D</strong>). The second model has access to some additional information from the environment - reward in case of AC and real data samples in case of GANs. These similarities suggest that heuristics and optimizations for one can be applied for the other.</p>

<p><img src="/blog/assets/img/why-do-GANs-matter/subtopic2.2.png" alt="Illustration of agent-environment setting like a GAN-pipeline" /></p>

<p>The GAN <strong>minimax</strong> game can be thought of as an agent-environment set up where the actor chooses to set pixels of the image. The environment then <em>stochastically</em> chooses to show a real image and give reward <strong>1</strong> or show the actions and give reward <strong>0</strong>. The critic has to predict what the reward is. Here the actor never actually sees the true environment analogous to the generator in GANs where it does not see the real data samples. They rely only on the gradient signal given by the other model. However, this is a sort of unusual setting where the actor does not get to influence the reward, hence making both components <strong>adversarial</strong> instead of cooperative.</p>

<h3 id="gans-in-medical-imaging">GANs in Medical Imaging</h3>

<p>GANs have received state-of-art performance in many image generation tasks. Their ability to create more data without explicitly learning probability density function has a huge scope in Computer Vision. There are two ways in which GANs can be applied in medical imaging. One is the use of a trained generator model to generate images of various body parts. Other is that the discriminator, trained on normal images can be used as a <strong>regularizer</strong> or <strong>detector</strong> for abnormal images. GANs have an edge over traditional ML approaches in medical imaging in terms of cell structure exploration and detecting abnormalities.</p>

<p><img src="/blog/assets/img/why-do-GANs-matter/subtopic3.png" alt="GANs in Medical Imaging" /></p>

<p><strong>Reconstruction</strong> is a major issue in medical imaging. Many times the image and scans obtained might have some noise or blurriness associated with it. This can be due to various reasons like patient comfort, constraints in clinical settings, etc. A <a href="https://arxiv.org/abs/1611.07004"><strong>pix2pix</strong></a> framework and pre-trained <a href="https://www.pyimagesearch.com/2017/03/20/imagenet-vggnet-resnet-inception-xception-keras/"><strong>VGG-net</strong></a> have been used to solve the problem but appreciable results are difficult to achieve in case of pumping organs like the heart. The use of <a href="https://arxiv.org/abs/1703.10593"><strong>CycleGAN</strong></a> has achieved improvement in cardiac CT denoising.</p>

<p>GANs have also been used for classification tasks in medicine. The semi-supervised training scheme of GANs for chest abnormality detection and cardiac disease diagnosis has achieved comparable results with the original supervised CNN approach with considerably less labeled data.</p>

<h3 id="liquid-warping-gans">Liquid Warping GANs</h3>

<p>Liquid Warping GAN is a unified approach towards <strong>Human Motion Imitation</strong>, <strong>Appearance Transfer</strong>, and <strong>Novel View Synthesis</strong>. These techniques are extremely useful in animation, video and game making, virtual clothes try-on, etc. Previous works separately handled these tasks with specific pipelines. Recently, GANs have proven to be useful in successfully solving all three tasks together. Motion imitation inputs a source image and a reference pose image and outputs the person in the former with a pose in the latter. Appearance Transfer is quite similar to <strong>Neural Style Transfer</strong> in Computer Vision, where the aim is to produce a human image preserving the reference identity with clothes (style). Novel View Synthesis aims to produce images of the person from different angles and views.</p>

<p><img src="/blog/assets/img/why-do-GANs-matter/subtopic4.1.png" alt="Human motion imitation, Appearance transfer, Novel view synthesis" /></p>

<p>As in many Computer Vision applications, traditional methods use 2D landmarking techniques to predict human body structure. However, these can capture only positional details with no modeling of limb rotations and characterization of body shape, which makes the output a bit less realistic. Using Liquid Warping GANs, we can capture the 3D body mesh and simultaneously preserve texture, color, style, and other finer details.</p>

<p>The pipeline consists of 3 stages which are same for all the three tasks:</p>

<h4 id="body-mesh-recovery">Body Mesh recovery</h4>
<p>In this module, the basic body structure, shape and 3D mesh of the person in source and reference images are reconstructed using <a href="https://arxiv.org/abs/1712.06584">Human Mesh Recovery</a> (HMR) which involves parsing of the image into a feature vector using <a href="https://arxiv.org/abs/1512.03385"><strong>ResNet-50</strong></a> followed by a regression network which predicts pose and shape. A bunch of parameters calculated as a function of pose and shape is passed to the next module in the pipeline.</p>

<h4 id="flow-composition">Flow Composition</h4>
<p>This step involves the construction of a map of the source and reference mesh followed by calculating the weighted geometric centroid coordinates of each mesh face. A <strong>transformation flow vector</strong> T is obtained and warped with the source image to get the warped image.</p>

<h4 id="liquid-warping-gan">Liquid Warping GAN</h4>
<p>This stage focuses on producing high-fidelity images with desired conditions like style, texture, etc. We use <strong>Liquid Warping Block</strong> (LWB) to preserve these conditions.</p>

<p><img src="/blog/assets/img/why-do-GANs-matter/subtopic4.2.png" alt="Liquid Warping Block" /></p>

<ul>
  <li>
    <p><strong>Generator</strong>: The generator works as 3 streams. The first stream of GANs works on generating a realistic background image. The second or source identity stream is a <em>convolutional auto-encoder</em> that identifies the source content, extracts the features required to keep the source details and reconstructs the source front image. The third or the transfer stream synthesizes the final result. LWB <strong>links</strong> the latter two streams. Advantage of using LWB is that it takes care of multiple sources, like in Appearance Transfer, preserving the head of source one and wearing the upper outer garment from the source two, while wearing the lower outer garment from the source three.</p>
  </li>
  <li>
    <p><strong>Discriminator</strong>: For discriminator, a <a href="https://arxiv.org/abs/1611.07004"><strong>pix2pix</strong></a> model is followed.</p>
  </li>
</ul>

<h2 id="references">References</h2>
<ol>
  <li><a href="https://arxiv.org/abs/1406.2661">Generative Adversarial Networks, Ian Goodfellow et al., 2014</a></li>
  <li><a href="https://arxiv.org/abs/1701.00160">GAN Tutorial, NIPS 2016</a></li>
  <li><a href="https://openai.com/blog/generative-models/">Open AI article on Generative Models</a></li>
</ol>

                </article>
                <div class="sidebar">
    <h1>Related Articles</h1>
    <div class="temp-div">
        <span id="category">CompSoc</span>
        <span id="title">Why do Generative Adversarial Nets matter?</span>
    </div>
    <div class="related-articles"></div>
</div>

            </div>

            <section class="author" itemprop="author">
    <div class="details" itemscope itemtype="http://schema.org/Person">
        <img itemprop="image" class="img-rounded" src="/blog/assets/img/authors/videh.png" alt="Videh Raj Nema">
        <p class="def">Author</p>
        <h3 class="name">
            <a itemprop="name" href="/">Videh Raj Nema</a>
        </h3>
        <p class="desc">Carpe Diem :)</p>
        <a itemprop="email" class="email" href="mailto:videhrn25@gmail.com">videhrn25@gmail.com</a>
    </div>
</section>

            <section class="comments">

	<div id="fb-root"></div>
	
	<script>(function(d, s, id) {
		var js, fjs = d.getElementsByTagName(s)[0];
		if (d.getElementById(id)) return;
		js = d.createElement(s); js.id = id;
		js.src = "//connect.facebook.net/en_US/sdk.js#xfbml=1&version=v2.5&appId=978128892233940";
		fjs.parentNode.insertBefore(js, fjs);
		}(document, 'script', 'facebook-jssdk'));
	</script>
</section>
            
            <section class="share">
    <h3>Share</h3>
    <a aria-label="Share on Twitter" href="https://twitter.com/intent/tweet?text=&quot;&quot;%20https://ieee.nitk.ac.in/blog/why-do-GANs-matter/%20via%20&#64;IEEE_NITK&hashtags=Deep Learning,Generative Adversarial Networks,GANs,Generative Models,Machine Learning,CompSoc,IEEE NITK,"
    onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;" title="Share on Twitter">
        <svg class="icon icon-twitter"><use xlink:href="#icon-twitter"></use></svg>
    </a>
    <a aria-label="Share on Facebook" href="https://www.facebook.com/sharer/sharer.php?u=https://ieee.nitk.ac.in//blog//why-do-GANs-matter/"
    onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;" title="Share on Facebook">
        <svg class="icon icon-facebook"><use xlink:href="#icon-facebook"></use></svg>
    </a>
    <a aria-label="Share on Google Plus" href="https://plus.google.com/share?url=https://ieee.nitk.ac.in//blog//why-do-GANs-matter/"
    onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;" title="Share on Google+">
        <svg class="icon icon-google-plus"><use xlink:href="#icon-google-plus"></use></svg>
    </a>
</section>

            <footer>
    <p>Made with <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> and <span class="love">❤</span> by <a href="https://ieeenitk.org">IEEE NITK</a></p>
</footer>
<script src="/blog/assets/js/main.js"></script>
            
<script>
	$(document).ready(function(){
		if($("pre code").length){
			
			$.getScript('../assets/js/highlight.pack.js', function(){
    			// load the highlighter script only if we have code snippets.
    			$('pre code').each(function(i, block) {
    				hljs.highlightBlock(block);
  				});	
    		});
		}
	});
</script>
        </section>

    </body>
</html>
            
